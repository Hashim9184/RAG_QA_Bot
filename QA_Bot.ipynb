{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing required Modules"
      ],
      "metadata": {
        "id": "3yJ9A5U3N6Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install openai==0.28\n",
        "!pip install pinecone-client\n",
        "!pip install tiktoken\n",
        "!pip install python-dotenv\n",
        "!pip install langchain\n",
        "!pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3CeT_1tNedV",
        "outputId": "765a0d8f-a82c-48e0-c8b8-6e6e35e16c3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2025.6.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.1)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.6.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.1)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.6.15)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.14.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.67)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.6.15)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.14.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.4.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.11/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries and dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "3TP_wAY6Mnhj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rIqQReWNMl_9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pinecone\n",
        "import tiktoken\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Env variable from .env file"
      ],
      "metadata": {
        "id": "6avkPX_SRd5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2b-f6aARjni",
        "outputId": "7ab4ed6a-d9e2-4ff6-c533-f47a2a129deb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "API's"
      ],
      "metadata": {
        "id": "rSxCxTIPRrul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = (\"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\")\n",
        "PINECONE_API_KEY = (\"pcsk_hppZ6_RACif1u2yyETwp4fYArdrz2yAMqvbpcm2ZtSUDZ8VLP1FBtxjwjBDrGYhS6VDRX\")\n",
        "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")  # e.g., \"gcp-starter\"\n",
        "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\", \"rag-business-qa\")\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\""
      ],
      "metadata": {
        "id": "K_-Hk8ZARtze"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "gDqSXyxoobu9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Pinecone Initialization ---"
      ],
      "metadata": {
        "id": "RZpvKjQ8R6O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)"
      ],
      "metadata": {
        "id": "lmiad1uTR9Jk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if index exists, if not, create it"
      ],
      "metadata": {
        "id": "THfk3z6kSAo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PINECONE_INDEX_NAME not in pc.list_indexes().names():\n",
        "    print(f\"Creating Pinecone index: {PINECONE_INDEX_NAME}\")\n",
        "    pc.create_index(\n",
        "        PINECONE_INDEX_NAME,\n",
        "        dimension=1536,  # Dimension for text-embedding-ada-002\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud='aws', region='us-east-1') # Added spec argument\n",
        "    )\n",
        "    print(f\"Index {PINECONE_INDEX_NAME} created.\")\n",
        "\n",
        "index = pc.Index(PINECONE_INDEX_NAME)"
      ],
      "metadata": {
        "id": "og3t3yxcSCMX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Text Processing and Embedding ---"
      ],
      "metadata": {
        "id": "wjYhjnA6SG22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, chunk_size=1000, overlap=200):\n",
        "    \"\"\"Splits text into chunks with optional overlap.\"\"\"\n",
        "    # Using tiktoken to handle tokenization which is better aligned with OpenAI models\n",
        "    tokenizer = tiktoken.encoding_for_model(EMBEDDING_MODEL)\n",
        "    tokens = tokenizer.encode(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), chunk_size - overlap):\n",
        "        chunk_tokens = tokens[i:i + chunk_size]\n",
        "        chunks.append(tokenizer.decode(chunk_tokens))\n",
        "    return chunks\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"Generates embedding for a given text using OpenAI.\"\"\"\n",
        "    try:\n",
        "        response = openai.Embedding.create(\n",
        "            input=text,\n",
        "            model=EMBEDDING_MODEL\n",
        "        )\n",
        "        return response['data'][0]['embedding']\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def index_document(doc_id, text):\n",
        "    \"\"\"Splits document, embeds chunks, and uploads to Pinecone.\"\"\"\n",
        "    chunks = split_text(text)\n",
        "    vectors_to_upsert = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        embedding = get_embedding(chunk)\n",
        "        if embedding:\n",
        "            vectors_to_upsert.append(\n",
        "                (\n",
        "                    f\"{doc_id}-{i}\",  # Unique ID for each chunk\n",
        "                    embedding,\n",
        "                    {\"text\": chunk, \"doc_id\": doc_id} # Metadata\n",
        "                )\n",
        "            )\n",
        "    if vectors_to_upsert:\n",
        "        index.upsert(vectors=vectors_to_upsert)\n",
        "        print(f\"Indexed {len(vectors_to_upsert)} chunks for document ID: {doc_id}\")\n",
        "    else:\n",
        "        print(f\"No chunks indexed for document ID: {doc_id}\")"
      ],
      "metadata": {
        "id": "P2Sl9SNSSIzn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---RAG Pipeline ---"
      ],
      "metadata": {
        "id": "3Kj9vV26SL2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_chunks(query, top_k=3):\n",
        "    \"\"\"Embeds query and retrieves top_k relevant chunks from Pinecone.\"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "    if query_embedding:\n",
        "        results = index.query(\n",
        "            vector=query_embedding,\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        return [match['metadata']['text'] for match in results['matches']]\n",
        "    return []\n",
        "\n",
        "def generate_answer(query, relevant_chunks):\n",
        "    \"\"\"Generates an answer using OpenAI based on the query and retrieved chunks.\"\"\"\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    # Construct the prompt for the language model\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following business information, answer the user's question.\n",
        "    If you cannot find the answer in the provided information, state that you don't have enough information to answer.\n",
        "\n",
        "    Business Information:\n",
        "    {context}\n",
        "\n",
        "    User Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for a business, answering questions based on provided context.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating answer with OpenAI: {e}\")\n",
        "        return \"An error occurred while generating the answer.\""
      ],
      "metadata": {
        "id": "ao7eUCiqSPV2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Indexing some sample business data\n",
        "-In a real application, you would load data from your business documents (PDFs, databases, etc.)"
      ],
      "metadata": {
        "id": "kS_SzHlsSTaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_business_data = {\n",
        "    \"doc1\": \"Our company provides cloud computing services, including Iaas, PaaS, and SaaS. We offer a 99.9% uptime guarantee for all our services.\",\n",
        "    \"doc2\": \"Our customer support is available 24/7 via email at support@example.com or by phone at 1-800-BUSINESS.\",\n",
        "    \"doc3\": \"We offer tiered pricing plans: Basic, Pro, and Enterprise. Visit our website for detailed pricing information.\"\n",
        "}\n",
        "\n",
        "print(\"Indexing sample business data...\")\n",
        "for doc_id, text in sample_business_data.items():\n",
        "    index_document(doc_id, text)\n",
        "print(\"Indexing complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAQTgeLnSgwO",
        "outputId": "789c5d2f-4817-478c-fb56-5a8134444696"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing sample business data...\n",
            "Error generating embedding: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
            "No chunks indexed for document ID: doc1\n",
            "Error generating embedding: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
            "No chunks indexed for document ID: doc2\n",
            "Error generating embedding: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
            "No chunks indexed for document ID: doc3\n",
            "Indexing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. QA Bot Interaction"
      ],
      "metadata": {
        "id": "9jIytFyXSjY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStarting Q&A bot. Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_query = input(\"Ask a question about the business: \")\n",
        "    if user_query.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    relevant_chunks = retrieve_relevant_chunks(user_query)\n",
        "\n",
        "    if not relevant_chunks:\n",
        "        print(\"Sorry, I couldn't find relevant information for that question.\")\n",
        "    else:\n",
        "        answer = generate_answer(user_query, relevant_chunks)\n",
        "        print(\"\\nAnswer:\", answer)\n",
        "        print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DJIbc4sSlZy",
        "outputId": "b3071e85-3f6f-466c-c6e7-6897c6007a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Q&A bot. Type 'quit' to exit.\n",
            "Ask a question about the business: what are the cloud computing services provided by our company\n",
            "Error generating embedding: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
            "Sorry, I couldn't find relevant information for that question.\n"
          ]
        }
      ]
    }
  ]
}